{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3974e3dd-4425-4f07-b17a-ee033fa9674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim  as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "93e27fa9-8c71-4035-9c57-ac5d0a4bfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Fully connected network\n",
    "\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_shape,output_shape):\n",
    "        super(NN,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,50)\n",
    "        self.fc2 = nn.Linear(50,output_shape)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0aea41ef-184c-4eb9-9be7-e25599c56e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715420ae-2ef7-4b12-8a60-ec37fa26443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_shape = 28*28\n",
    "output_shape = 10\n",
    "batch = 100\n",
    "num_epoch = 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3a80d-e8a9-48e7-81f6-6a582a8bfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load Dataset\n",
    "train_dataset = datasets.MNIST(root = 'datasets/',train=True,download=True,transform = transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch,shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = 'datasets/',train=False,download=True,transform = transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86711cc3-81d9-4f48-b639-68f8caec1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize model \n",
    "model = NN(input_shape,output_shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62baa89-f70d-42c3-9078-40be5104e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Losss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1ad25a2f-4b16-4e7d-9a8c-c861272e7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5edc1-dfd4-4e03-92c7-7eb19abde980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.317837715148926\n",
      "loss 1.968946933746338\n",
      "loss 1.5687601566314697\n",
      "loss 1.2299234867095947\n",
      "loss 0.9487663507461548\n",
      "loss 0.7027846574783325\n",
      "loss 0.49761566519737244\n",
      "loss 0.3345147371292114\n",
      "loss 0.22157350182533264\n",
      "loss 0.14929834008216858\n"
     ]
    }
   ],
   "source": [
    "## Train Network \n",
    "for epoch in range(num_epoch):\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        # Get data to cuda \n",
    "        data = data.to(device=device)\n",
    "        target =target.to(device=device)\n",
    "        \n",
    "        # reshape\n",
    "        data = data.view(data.shape[0],-1)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,target)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"loss {sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6f1cb1d2-9211-4722-a4ff-49598935c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy of out trained model \n",
    "def check_accuracy(loader,model):\n",
    "    for data,target in loader:\n",
    "        num_correct = 0\n",
    "        num_sample = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "            # reshape \n",
    "            data = data.view(data.shape[0],-1)\n",
    "\n",
    "\n",
    "            scores = model(data)\n",
    "            _, pred = scores.max(1)\n",
    "            # print(list(zip(pred,target)))\n",
    "            num_correct += sum(pred == target)\n",
    "            num_sample  += pred.shape[0]\n",
    "    print(f'Total {num_correct} correct  / out of {num_sample} - accuracy {num_correct/num_sample :.3f} ')\n",
    "    model.train()\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "beaeb0b5-28c4-4d9e-90eb-4c3bda7f43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 100 correct  / out of 100 - accuracy 1.000 \n"
     ]
    }
   ],
   "source": [
    "# on test dataset\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cc0beb2f-db8c-4a0f-867b-ec4ba828f3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 99 correct  / out of 100 - accuracy 0.990 \n"
     ]
    }
   ],
   "source": [
    "# on train datasets\n",
    "check_accuracy(train_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65432fa-0127-4537-a73e-b67fc450dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.24650805016358693\n",
      "loss 0.13312209708616138\n",
      "loss 0.1078857210286272\n",
      "loss 0.09726110332102204\n",
      "loss 0.0843132480699569\n",
      "loss 0.07796743455769804\n",
      "loss 0.07122201545280404\n",
      "loss 0.07191215923133616\n",
      "loss 0.062184439715347255\n",
      "loss 0.06702433424177191\n",
      "Total 95 correct  / out of 100 - accuracy 0.950 \n",
      "Total 98 correct  / out of 100 - accuracy 0.980 \n",
      "Elapsed time: 82.80084 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim  as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms\n",
    "# Import intel_extension_for_pytorch\n",
    "# import intel_extension_for_pytorch as ipex\n",
    "import time\n",
    "## Create Fully connected network\n",
    "start_time = time.time()\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_shape,output_shape):\n",
    "        super(NN,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,50)\n",
    "        self.fc2 = nn.Linear(50,output_shape)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = 28*28\n",
    "output_shape = 10\n",
    "batch = 100\n",
    "num_epoch = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "## load Dataset\n",
    "train_dataset = datasets.MNIST(root = 'datasets/',train=True,download=True,transform = transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch,shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = 'datasets/',train=False,download=True,transform = transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch,shuffle=True)\n",
    "\n",
    "## Initialize model \n",
    "model = NN(input_shape,output_shape).to(device)\n",
    "\n",
    "## Losss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "## Train Network \n",
    "for epoch in range(num_epoch):\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        # Get data to cuda \n",
    "        data = data.to(device=device)\n",
    "        target =target.to(device=device)\n",
    "        \n",
    "        # reshape\n",
    "        data = data.view(data.shape[0],-1)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,target)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"loss {sum(losses)/len(losses)}\")\n",
    "# check the accuracy of out trained model \n",
    "def check_accuracy(loader,model):\n",
    "    for data,target in loader:\n",
    "        num_correct = 0\n",
    "        num_sample = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "            # reshape \n",
    "            data = data.view(data.shape[0],-1)\n",
    "\n",
    "\n",
    "            scores = model(data)\n",
    "            _, pred = scores.max(1)\n",
    "            # print(list(zip(pred,target)))\n",
    "            num_correct += sum(pred == target)\n",
    "            num_sample  += pred.shape[0]\n",
    "    print(f'Total {num_correct} correct  / out of {num_sample} - accuracy {num_correct/num_sample :.3f} ')\n",
    "    model.train()\n",
    "            \n",
    "            \n",
    "            \n",
    "# on test dataset\n",
    "check_accuracy(test_loader,model)\n",
    "\n",
    "# on train datasets\n",
    "check_accuracy(train_loader,model)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time: {:.5f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a89525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
