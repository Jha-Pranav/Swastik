{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21fcadd8-efe4-4546-aaef-389d05319108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter # print to tensorboard\n",
    "import torchvision\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "import requests\n",
    "\n",
    "@register_cell_magic\n",
    "def execute_remotely(line, cell):\n",
    "    code = cell.strip()\n",
    "    response = requests.post('http://192.168.0.105:2408/execute', data={'code': code})\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ca1bf7-df42-4b61-9adf-c70cd9a1bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1270756-f43d-4761-9c24-c1bf55303250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constructor\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_channel,n_out):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channel,out_channels=8,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "        self.conv2 =nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.fc1 = nn.Linear(in_features=16*7*7,out_features=n_out)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x =  F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b5d42f3-402a-4de4-9fe4-6824a3b98a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model_checkpoints/cnn-checkpoint.pth.tar\"\n",
    "def save_checkpoint(epoch,model,optimizer,loss,PATH=path):\n",
    "    print('==> Saving Checkpoint')\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, PATH)\n",
    "    \n",
    "def load_checkpoint(model,optimizer,PATH=path):\n",
    "    \n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model , optimizer, epoch,loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e40aae97-efc6-475d-9b83-3e134267c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "n_channel = 1\n",
    "n_out = 10\n",
    "learing_rate = 0.01\n",
    "n_epochs = 2\n",
    "batch = 100\n",
    "load_model = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4aca7e-dd1e-42a8-9c11-b70438464e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "train_data = datasets.MNIST(root='datasets/',train= True,download=True, transform= transforms.ToTensor())\n",
    "train_loader =DataLoader(train_data,batch,True)\n",
    "\n",
    "test_data = datasets.MNIST(root='datasets/',train= False,download=True, transform= transforms.ToTensor())\n",
    "test_loader =DataLoader(test_data,batch,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bccc94ba-208f-4761-a2fd-4b98096fe887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model \n",
    "\n",
    "model = CNN(n_channel,n_out).to(device= device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b317a53a-2ee3-438a-aa34-b00473cbe713",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr= learing_rate)\n",
    "writer = SummaryWriter('runs/MNIST/trying_out_tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c5e53c1-6816-4b99-9bfc-3281fc02e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Load Model\n",
      "Last Trained:  epoch 14, loss 0.340\n"
     ]
    }
   ],
   "source": [
    "last_trained_epoch = 0\n",
    "if load_model:\n",
    "    model, optimizer, last_trained_epoch, loss = load_checkpoint(model,optimizer)\n",
    "    print('==> Load Model', )\n",
    "    print(f'Last Trained:  epoch {last_trained_epoch}, loss {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50650773-5041-4313-9c32-9f98abe689a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Executing remotly\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%execute_remotely\n",
    "batches= [128,1024]\n",
    "\n",
    "learing_rate = [0.01,0.001]\n",
    "classes = list('0123456789')\n",
    "\n",
    "\n",
    "for batch in batches:\n",
    "    for lr in learing_rate:\n",
    "        train_loader =DataLoader(train_data,batch,True)\n",
    "        model = CNN(n_channel,n_out).to(device= device)\n",
    "        optimizer = optim.Adam(model.parameters(),lr= lr)\n",
    "        writer = SummaryWriter(f'runs/MNIST/mnist batch {batch} lr {lr}')\n",
    "        ## Train Network \n",
    "        step = 0\n",
    "        for epoch in range(1,n_epochs):\n",
    "\n",
    "            if (epoch % 2 == 0) and (epoch != 0):\n",
    "                print(f'Loss at epoch {epoch} was {sum(losses)/len(losses):.3f}')\n",
    "                save_checkpoint(last_trained_epoch+epoch,model,optimizer,sum(losses)/len(losses))\n",
    "\n",
    "            losses = []\n",
    "            accuracy = []\n",
    "\n",
    "\n",
    "            for batch_idx, (data,target) in enumerate(train_loader):\n",
    "                # Get data to cuda \n",
    "                data = data.to(device=device)\n",
    "                target =target.to(device=device)\n",
    "\n",
    "                # forward\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores,target)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "\n",
    "                # backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                # gradient descent\n",
    "                optimizer.step()\n",
    "                \n",
    "\n",
    "\n",
    "                # running training accuracy \n",
    "                _, predictions = scores.max(1)\n",
    "                num_correct = (predictions == target).sum()\n",
    "                running_acc = num_correct/data.shape[0]\n",
    "                accuracy.append(running_acc)\n",
    "                \n",
    "                # print to tensorboard\n",
    "                class_labels = [classes[label] for label in predictions]\n",
    "                writer.add_scalar('Training Loss',loss,step)\n",
    "                writer.add_scalar('Training Accuracy',running_acc,step)\n",
    "                img_grid = torchvision.utils.make_grid(data)\n",
    "                writer.add_image('mnist_images/',img_grid)\n",
    "                writer.add_histogram('fc1',model.fc1.weight)\n",
    "                writer.add_embedding(data.reshape(data.shape[0],-1),metadata=class_labels,label_img=data,global_step=step)\n",
    "                step += 1\n",
    "            writer.add_hparams({'batch':batch,'lr':lr},\n",
    "                              {'accuracy':sum(accuracy)/len(accuracy),\n",
    "                              'loss':sum(losses)/len(losses)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31455100-8706-4112-863f-17cfa0e0f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy of out trained model \n",
    "def check_accuracy(loader,model):\n",
    "    for data,target in loader:\n",
    "        num_correct = 0\n",
    "        num_sample = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "\n",
    "            scores = model(data)\n",
    "            _, pred = scores.max(1)\n",
    "            # print(list(zip(pred,target)))\n",
    "            num_correct += sum(pred == target)\n",
    "            num_sample  += pred.shape[0]\n",
    "    print(f'Total {num_correct} correct  / out of {num_sample} - accuracy {num_correct/num_sample :.3f} ')\n",
    "    model.train()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b538a87-f437-45e1-a618-10b36e288058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 99 correct  / out of 100 - accuracy 0.990 \n"
     ]
    }
   ],
   "source": [
    "# on test dataset\n",
    "check_accuracy(test_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7fcc8b0b-3aa2-4c7d-9499-08cbd6e2f294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 99 correct  / out of 100 - accuracy 0.990 \n"
     ]
    }
   ],
   "source": [
    "# on train datasets\n",
    "check_accuracy(train_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2662cbc5-11c2-4bc5-a697-60762dd31948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss 0.2552393776985506\\nloss 0.13096148609028507\\nloss 0.10714676157881817\\nloss 0.09570716719958\\nloss 0.0882464286343505\\nloss 0.07825754644776074\\nloss 0.07478912472336864\\nloss 0.07197097798644488\\nloss 0.07139894454972819\\nloss 0.06705103664979106\\nTotal 99 correct  / out of 100 - accuracy 0.990 \\nTotal 97 correct  / out of 100 - accuracy 0.970 \\nElapsed time: 189.51283 seconds\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%execute_remotely\n",
    "## Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim  as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms\n",
    "# Import intel_extension_for_pytorch\n",
    "# import intel_extension_for_pytorch as ipex\n",
    "import time\n",
    "## Create Fully connected network\n",
    "start_time = time.time()\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_shape,output_shape):\n",
    "        super(NN,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,50)\n",
    "        self.fc2 = nn.Linear(50,output_shape)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# Hyperparameters\n",
    "input_shape = 28*28\n",
    "output_shape = 10\n",
    "batch = 100\n",
    "num_epoch = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "## load Dataset\n",
    "train_dataset = datasets.MNIST(root = 'datasets/',train=True,download=True,transform = transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch,shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root = 'datasets/',train=False,download=True,transform = transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=test_dataset,batch_size=batch,shuffle=True)\n",
    "\n",
    "## Initialize model \n",
    "model = NN(input_shape,output_shape).to(device)\n",
    "\n",
    "## Losss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "## Train Network \n",
    "for epoch in range(num_epoch):\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        # Get data to cuda \n",
    "        data = data.to(device=device)\n",
    "        target =target.to(device=device)\n",
    "        \n",
    "        # reshape\n",
    "        data = data.view(data.shape[0],-1)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores,target)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"loss {sum(losses)/len(losses)}\")\n",
    "# check the accuracy of out trained model \n",
    "def check_accuracy(loader,model):\n",
    "    for data,target in loader:\n",
    "        num_correct = 0\n",
    "        num_sample = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device=device)\n",
    "            target = target.to(device=device)\n",
    "\n",
    "            # reshape \n",
    "            data = data.view(data.shape[0],-1)\n",
    "\n",
    "\n",
    "            scores = model(data)\n",
    "            _, pred = scores.max(1)\n",
    "            # print(list(zip(pred,target)))\n",
    "            num_correct += sum(pred == target)\n",
    "            num_sample  += pred.shape[0]\n",
    "    print(f'Total {num_correct} correct  / out of {num_sample} - accuracy {num_correct/num_sample :.3f} ')\n",
    "    model.train()\n",
    "            \n",
    "            \n",
    "            \n",
    "# on test dataset\n",
    "check_accuracy(test_loader,model)\n",
    "\n",
    "# on train datasets\n",
    "check_accuracy(train_loader,model)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed time: {:.5f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47685215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1585471666666667"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "189.51283/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3249a99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error executing code:   File \"<string>\", line 1\\n    !pip3 install intel-extension-for-pytorch\\n    ^\\nSyntaxError: invalid syntax\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%execute_remotely\n",
    "!pip3 install intel-extension-for-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "949e6006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Error executing code: Traceback (most recent call last):\\n  File \"<string>\", line 1, in <module>\\nModuleNotFoundError: No module named \\'intel_extension_for_pytorch\\'\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%execute_remotely\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "print(ipex.xpu.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5d9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
